# Лабораторная работа №2

## Цель работы

Изучение технологии параллельного программирования OpenMP и получение практических навыков распараллеливания вычислительных алгоритмов. Сравнение производительности последовательной и параллельной реализаций выбранного алгоритма из набора тестов PolyBench.

## Ход работы

Для реализации данной лабораторной работы был выбран алгоритм **ATAX** (matrix-vector multiplication followed by transpose multiplication). Алгоритм выполняет операцию \( y = A^T \cdot (A \cdot x) \), где:

- \( A \) — матрица размером \( N \times N \)
- \( x \) — входной вектор размером \( N \)
- \( y \) — результирующий вектор размером \( N \)
- \( tmp \) — промежуточный вектор для хранения результата \( A \cdot x \)

**Вычислительная сложность:** \( O(N^2) \) операций с плавающей точкой.

## Реализация алгоритма на языке программирования Си

### Последовательный алгоритм

```c
// Этап 1: tmp = A * x
for (int i = 0; i < N; i++) {
    tmp[i] = 0.0;
    for (int j = 0; j < N; j++) {
        tmp[i] += A[i * N + j] * x[j];
    }
}

// Этап 2: y = A^T * tmp
for (int j = 0; j < N; j++) {
    y[j] = 0.0;
    for (int i = 0; i < N; i++) {
        y[j] += A[i * N + j] * tmp[i];
    }
}
```


Каждый этап выполняется последовательно, итерация за итерацией.

### Параллельный алгоритм

```c
// Этап 1: параллельное вычисление tmp = A * x
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    tmp[i] = 0.0;
    for (int j = 0; j < N; j++) {
        tmp[i] += A[i * N + j] * x[j];
    }
}

// Этап 2: параллельное вычисление y = A^T * tmp
#pragma omp parallel for
for (int j = 0; j < N; j++) {
    y[j] = 0.0;
    for (int i = 0; i < N; i++) {
        y[j] += A[i * N + j] * tmp[i];
    }
}
```


Для реализации параллельного алгоритма использовалась директива `#pragma omp parallel for`.

Эта директива распараллеливает цикл `for`, автоматически разделяя итерации между доступными потоками. Каждый поток обрабатывает свою часть итераций независимо.

**Принцип работы параллелизации:**

- Директива `#pragma omp parallel for` создаёт команду потоков
- Итерации внешнего цикла автоматически распределяются между потоками
- Каждый поток вычисляет свои элементы массивов `tmp` и `y` независимо
- Отсутствуют race conditions, так как каждый поток записывает в уникальные ячейки памяти

## Методика тестирования

### Инициализация данных

Использован генератор псевдослучайных чисел на основе линейного конгруэнтного метода с параллельной инициализацией:

```c
#pragma omp parallel
{
    int seed = (seed_time + omp_get_thread_num()) % MODULUS;
    #pragma omp for
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            A[i * N + j] = linear_congruential_gen(&seed) * N;
        }
    }
}
```


Каждый поток использует свой seed для генерации, что обеспечивает детерминированность результатов.

### Измерение времени выполнения

Для измерения времени использована функция `gettimeofday()` с точностью до микросекунд:

```c
struct timeval start_time, finish_time;
gettimeofday(&start_time, 0);
// ... код ядра ...
gettimeofday(&finish_time, 0);
float elapsed = elapsed_msecs(start_time, finish_time);
```


### Проверка корректности

Сравнение результатов последовательной и параллельной версий через вычисление максимальной относительной погрешности:

```c
double max_diff = 0;
for (int i = 0; i < N; i++) {
    double diff = fabs(y_par[i] / y_seq[i] - 1);
    if (diff > max_diff)
        max_diff = diff;
}
```


## Результаты

### Тест №1

**N = 5000**

| Параметр | Значение |
|----------|----------|
| Размер матрицы | 5000×5000 |
| Время последовательной версии | 132.843994 мс |
| Время параллельной версии | 38.168999 мс |
| Ускорение (Speedup) | 3.48x |
| Максимальная разница результатов | 0.000000% |

**Ускорение:**

\[
\text{Speedup} = \frac{T_{\text{sequential}}}{T_{\text{parallel}}} = \frac{132.843994}{38.168999} \approx 3.48
\]

**Эффективность распараллеливания:**

\[
\text{Efficiency} = \frac{\text{Speedup}}{N_{\text{threads}}} \times 100\%
\]

В тестах участвовал процессор с 8 потоками:

\[
\text{Efficiency} = \frac{3.48}{8} \times 100\% \approx 43.5\%
\]

### Тест №2

**N = 10000**

| Параметр | Значение |
|----------|----------|
| Размер матрицы | 10000×10000 |
| Время последовательной версии | 899.27301 мс |
| Время параллельной версии | 146.649002 мс |
| Ускорение (Speedup) | 6.13x |
| Максимальная разница результатов | 0.000000% |

**Ускорение:**

\[
\text{Speedup} = \frac{T_{\text{sequential}}}{T_{\text{parallel}}} = \frac{899.273010}{146.649002} \approx 6.13
\]

**Эффективность распараллеливания:**

\[
\text{Efficiency} = \frac{\text{Speedup}}{N_{\text{threads}}} \times 100\%
\]

В тестах участвовал процессор с 8 потоками:

\[
\text{Efficiency} = \frac{6.13}{8} \times 100\% \approx 76.625\%
\]

## Анализ результатов

Проведено два теста с различными размерами задачи для анализа масштабируемости параллелизации:

**Тест №1 (N = 5000):**
- Ускорение: 3.48x
- Эффективность: 43.5%
- Время последовательной версии: 132.84 мс
- Время параллельной версии: 38.17 мс

**Тест №2 (N = 10000):**
- Ускорение: 6.13x
- Эффективность: 76.6%
- Время последовательной версии: 899.27 мс
- Время параллельной версии: 146.65 мс

### Зависимость эффективности от размера задачи

При увеличении размера матрицы с 5000×5000 до 10000×10000 наблюдается значительный рост эффективности распараллеливания с 43.5% до 76.6%.

**Причины роста эффективности:**

- **Амортизация overhead'а:** При малых N накладные расходы на создание потоков, их синхронизацию и распределение работы составляют значительную долю от общего времени выполнения
- **Увеличение объёма вычислений:** Вычислительная сложность алгоритма O(N²) означает, что при увеличении N в 2 раза объём вычислений растёт в 4 раза (с 25M до 100M операций)
- **Лучшая утилизация процессора:** При больших N каждый поток получает достаточно работы для эффективной загрузки процессорного ядра

### Корректность параллелизации

Максимальная разница результатов между последовательной и параллельной версиями составила 0.000000% для обоих тестов. Это подтверждает:

- Отсутствие race conditions в коде
- Детерминированность вычислений
- Правильное распределение итераций между потоками
- Независимость итераций циклов

### Достоинства реализации

- **Простота распараллеливания:** Использование директивы `#pragma omp parallel for` требует минимальных изменений в коде
- **Хорошая масштабируемость:** Рост эффективности с увеличением размера задачи показывает потенциал для работы с большими данными
- **Предсказуемость результатов:** Абсолютная идентичность результатов упрощает верификацию

### Факторы, ограничивающие ускорение

- **Накладные расходы OpenMP:** Создание потоков, их синхронизация и планирование итераций требуют времени
- **Закон Амдала:** Теоретический максимум ускорения на 8 потоках — 8×, но практически недостижим из-за последовательных участков кода
- **Конкуренция за память:** Параллельный доступ к памяти создаёт конкуренцию за шину памяти и кэш-линии
- **Cache locality:** При распределении итераций между потоками возможны промахи кэша

## Выводы

Для алгоритма ATAX оптимальный размер задачи для эффективного распараллеливания — N ≥ 10000. При меньших размерах overhead от параллелизма может не окупаться. Достигнутая эффективность 76.6% на 8 потоках для N = 10000 является хорошим результатом для данного класса задач.
